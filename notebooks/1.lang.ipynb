{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7acf66fe-b3c8-4592-b6bd-79592f6ba79e",
   "metadata": {},
   "source": [
    "# Simple question and answer app\n",
    "\n",
    "  working here  \n",
    "  https://learn.deeplearning.ai/courses/langchain/lesson/5/question-and-answer  \n",
    "\n",
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b0c77ff-aa87-4381-b97c-c43bcb58dd69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-dotenv\n",
      "  Using cached python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.0.1\n"
     ]
    }
   ],
   "source": [
    "#!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10acf4e1-e8fc-4f78-bf68-9edf3d721312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-1.14.3-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/codespace/.local/lib/python3.10/site-packages (from openai) (4.3.0)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/codespace/.local/lib/python3.10/site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from openai) (2.6.4)\n",
      "Requirement already satisfied: sniffio in /home/codespace/.local/lib/python3.10/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from openai) (4.64.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /home/codespace/.local/lib/python3.10/site-packages (from openai) (4.10.0)\n",
      "Requirement already satisfied: idna>=2.8 in /home/codespace/.local/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/codespace/.local/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
      "Requirement already satisfied: certifi in /home/codespace/.local/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /home/codespace/.local/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.4)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/codespace/.local/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (2.16.3)\n",
      "Downloading openai-1.14.3-py3-none-any.whl (262 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m262.9/262.9 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Installing collected packages: distro, openai\n",
      "Successfully installed distro-1.9.0 openai-1.14.3\n"
     ]
    }
   ],
   "source": [
    "#!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5b6195a-03f1-4b1d-be2a-14baad2f5808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: python-dotenv\n",
      "Version: 1.0.1\n",
      "Summary: Read key-value pairs from a .env file and set them as environment variables\n",
      "Home-page: https://github.com/theskumar/python-dotenv\n",
      "Author: Saurabh Kumar\n",
      "Author-email: me+github@saurabh-kumar.com\n",
      "License: BSD-3-Clause\n",
      "Location: /usr/local/python/3.10.13/lib/python3.10/site-packages\n",
      "Requires: \n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "#!pip show python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df0ed01d-b028-44f4-8389-7ee5dc8a9ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd5be4cd-e519-4fad-a914-11e8b3ec09ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']\n",
    "#print(f\"openai.api_key: {openai.api_key}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51ceb455-01ca-455a-93e8-bbfab0235953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llm_model: gpt-3.5-turbo-0301\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# account for deprecation of LLM model\n",
    "import datetime\n",
    "# Get the current date\n",
    "current_date = datetime.datetime.now().date()\n",
    "\n",
    "# Define the date after which the model should be set to \"gpt-3.5-turbo\"\n",
    "target_date = datetime.date(2024, 6, 12)\n",
    "\n",
    "# Set the model variable based on the current date\n",
    "if current_date > target_date:\n",
    "    llm_model = \"gpt-3.5-turbo\"\n",
    "else:\n",
    "    llm_model = \"gpt-3.5-turbo-0301\"\n",
    "\n",
    "print(f\"llm_model: {llm_model}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfce86d5-01e5-4484-b1d4-32d36f6c0076",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import CSVLoader\n",
    "from langchain.vectorstores import DocArrayInMemorySearch\n",
    "from IPython.display import display, Markdown\n",
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad15786e-04ce-4f85-a462-11b2dfb19137",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = '../data/OutdoorClothingCatalog_1000.csv'\n",
    "loader = CSVLoader(file_path=file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ebf0dc24-49c8-4b49-bd24-5a0dc49283d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.indexes import VectorstoreIndexCreator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "158000dd-8c99-494c-be70-a544f9f78c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting docarray\n",
      "  Downloading docarray-0.40.0-py3-none-any.whl.metadata (36 kB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from docarray) (1.24.2)\n",
      "Requirement already satisfied: orjson>=3.8.2 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from docarray) (3.10.0)\n",
      "Requirement already satisfied: pydantic>=1.10.8 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from docarray) (2.6.4)\n",
      "Collecting rich>=13.1.0 (from docarray)\n",
      "  Downloading rich-13.7.1-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting types-requests>=2.28.11.6 (from docarray)\n",
      "  Downloading types_requests-2.31.0.20240311-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from docarray) (0.9.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from pydantic>=1.10.8->docarray) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from pydantic>=1.10.8->docarray) (2.16.3)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /home/codespace/.local/lib/python3.10/site-packages (from pydantic>=1.10.8->docarray) (4.10.0)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=13.1.0->docarray)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/codespace/.local/lib/python3.10/site-packages (from rich>=13.1.0->docarray) (2.17.2)\n",
      "Requirement already satisfied: urllib3>=2 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from types-requests>=2.28.11.6->docarray) (2.0.7)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from typing-inspect>=0.8.0->docarray) (1.0.0)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=13.1.0->docarray)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading docarray-0.40.0-py3-none-any.whl (270 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m270.2/270.2 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading rich-13.7.1-py3-none-any.whl (240 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.7/240.7 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading types_requests-2.31.0.20240311-py3-none-any.whl (14 kB)\n",
      "Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: types-requests, mdurl, markdown-it-py, rich, docarray\n",
      "Successfully installed docarray-0.40.0 markdown-it-py-3.0.0 mdurl-0.1.2 rich-13.7.1 types-requests-2.31.0.20240311\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# !pip install docarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24d56bf2-e087-4f15-aac1-00e78969cdaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.10.13/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.embeddings.openai.OpenAIEmbeddings` was deprecated in langchain-community 0.0.9 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Could not import tiktoken python package. This is needed in order to for OpenAIEmbeddings. Please install it with `pip install tiktoken`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/python/3.10.13/lib/python3.10/site-packages/langchain_community/embeddings/openai.py:450\u001b[0m, in \u001b[0;36mOpenAIEmbeddings._get_len_safe_embeddings\u001b[0;34m(self, texts, engine, chunk_size)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 450\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtiktoken\u001b[39;00m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tiktoken'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m index \u001b[38;5;241m=\u001b[39m \u001b[43mVectorstoreIndexCreator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvectorstore_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDocArrayInMemorySearch\u001b[49m\n\u001b[0;32m----> 3\u001b[0m \u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_loaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mloader\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/python/3.10.13/lib/python3.10/site-packages/langchain/indexes/vectorstore.py:113\u001b[0m, in \u001b[0;36mVectorstoreIndexCreator.from_loaders\u001b[0;34m(self, loaders)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m loader \u001b[38;5;129;01min\u001b[39;00m loaders:\n\u001b[1;32m    112\u001b[0m     docs\u001b[38;5;241m.\u001b[39mextend(loader\u001b[38;5;241m.\u001b[39mload())\n\u001b[0;32m--> 113\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/python/3.10.13/lib/python3.10/site-packages/langchain/indexes/vectorstore.py:126\u001b[0m, in \u001b[0;36mVectorstoreIndexCreator.from_documents\u001b[0;34m(self, documents)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Create a vectorstore index from documents.\"\"\"\u001b[39;00m\n\u001b[1;32m    125\u001b[0m sub_docs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext_splitter\u001b[38;5;241m.\u001b[39msplit_documents(documents)\n\u001b[0;32m--> 126\u001b[0m vectorstore \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvectorstore_cls\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43msub_docs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvectorstore_kwargs\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m VectorStoreIndexWrapper(vectorstore\u001b[38;5;241m=\u001b[39mvectorstore)\n",
      "File \u001b[0;32m/usr/local/python/3.10.13/lib/python3.10/site-packages/langchain_core/vectorstores.py:550\u001b[0m, in \u001b[0;36mVectorStore.from_documents\u001b[0;34m(cls, documents, embedding, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m texts \u001b[38;5;241m=\u001b[39m [d\u001b[38;5;241m.\u001b[39mpage_content \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[1;32m    549\u001b[0m metadatas \u001b[38;5;241m=\u001b[39m [d\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[0;32m--> 550\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/python/3.10.13/lib/python3.10/site-packages/langchain_community/vectorstores/docarray/in_memory.py:69\u001b[0m, in \u001b[0;36mDocArrayInMemorySearch.from_texts\u001b[0;34m(cls, texts, embedding, metadatas, **kwargs)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Create an DocArrayInMemorySearch store and insert data.\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \n\u001b[1;32m     56\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;124;03m    DocArrayInMemorySearch Vector Store\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     68\u001b[0m store \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mfrom_params(embedding, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 69\u001b[0m \u001b[43mstore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadatas\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m store\n",
      "File \u001b[0;32m/usr/local/python/3.10.13/lib/python3.10/site-packages/langchain_community/vectorstores/docarray/base.py:82\u001b[0m, in \u001b[0;36mDocArrayIndex.add_texts\u001b[0;34m(self, texts, metadatas, **kwargs)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Embed texts and add to the vector store.\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \n\u001b[1;32m     74\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;124;03m    List of ids from adding the texts into the vectorstore.\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     81\u001b[0m ids: List[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 82\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (t, e) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(texts, embeddings)):\n\u001b[1;32m     84\u001b[0m     m \u001b[38;5;241m=\u001b[39m metadatas[i] \u001b[38;5;28;01mif\u001b[39;00m metadatas \u001b[38;5;28;01melse\u001b[39;00m {}\n",
      "File \u001b[0;32m/usr/local/python/3.10.13/lib/python3.10/site-packages/langchain_community/embeddings/openai.py:668\u001b[0m, in \u001b[0;36mOpenAIEmbeddings.embed_documents\u001b[0;34m(self, texts, chunk_size)\u001b[0m\n\u001b[1;32m    665\u001b[0m \u001b[38;5;66;03m# NOTE: to keep things simple, we assume the list may contain texts longer\u001b[39;00m\n\u001b[1;32m    666\u001b[0m \u001b[38;5;66;03m#       than the maximum context and use length-safe embedding function.\u001b[39;00m\n\u001b[1;32m    667\u001b[0m engine \u001b[38;5;241m=\u001b[39m cast(\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeployment)\n\u001b[0;32m--> 668\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_len_safe_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/python/3.10.13/lib/python3.10/site-packages/langchain_community/embeddings/openai.py:452\u001b[0m, in \u001b[0;36mOpenAIEmbeddings._get_len_safe_embeddings\u001b[0;34m(self, texts, engine, chunk_size)\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtiktoken\u001b[39;00m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m--> 452\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m    453\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not import tiktoken python package. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    454\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis is needed in order to for OpenAIEmbeddings. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    455\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease install it with `pip install tiktoken`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    456\u001b[0m     )\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    459\u001b[0m     encoding \u001b[38;5;241m=\u001b[39m tiktoken\u001b[38;5;241m.\u001b[39mencoding_for_model(model_name)\n",
      "\u001b[0;31mImportError\u001b[0m: Could not import tiktoken python package. This is needed in order to for OpenAIEmbeddings. Please install it with `pip install tiktoken`."
     ]
    }
   ],
   "source": [
    "## CONTINUE HERE\n",
    "\n",
    "index = VectorstoreIndexCreator(\n",
    "    vectorstore_cls=DocArrayInMemorySearch\n",
    ").from_loaders([loader])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2d246c8c-b1ae-44d8-8208-153ddab51edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aiohttp==3.9.3\n",
      "aiosignal==1.3.1\n",
      "annotated-types==0.6.0\n",
      "anyio==4.3.0\n",
      "argon2-cffi==23.1.0\n",
      "argon2-cffi-bindings==21.2.0\n",
      "arrow==1.3.0\n",
      "asttokens==2.4.1\n",
      "async-lru==2.0.4\n",
      "async-timeout==4.0.3\n",
      "attrs==23.2.0\n",
      "Babel==2.14.0\n",
      "beautifulsoup4==4.12.3\n",
      "bleach==6.1.0\n",
      "certifi==2024.2.2\n",
      "cffi==1.16.0\n",
      "charset-normalizer==3.3.2\n",
      "colorama==0.4.6\n",
      "comm==0.2.2\n",
      "contourpy==1.2.0\n",
      "cycler==0.12.1\n",
      "dataclasses-json==0.6.4\n",
      "debugpy==1.8.1\n",
      "decorator==5.1.1\n",
      "defusedxml==0.7.1\n",
      "distro==1.9.0\n",
      "exceptiongroup==1.2.0\n",
      "executing==2.0.1\n",
      "fastjsonschema==2.19.1\n",
      "filelock==3.13.1\n",
      "fonttools==4.50.0\n",
      "fqdn==1.5.1\n",
      "frozenlist==1.4.1\n",
      "fsspec==2024.3.1\n",
      "gitdb==4.0.11\n",
      "GitPython==3.1.42\n",
      "greenlet==3.0.3\n",
      "h11==0.14.0\n",
      "httpcore==1.0.4\n",
      "httpx==0.27.0\n",
      "idna==3.6\n",
      "ipykernel==6.29.3\n",
      "ipython==8.22.2\n",
      "ipython-genutils==0.2.0\n",
      "ipywidgets==7.7.1\n",
      "isoduration==20.11.0\n",
      "jedi==0.19.1\n",
      "Jinja2==3.1.3\n",
      "joblib==1.3.2\n",
      "json5==0.9.24\n",
      "jsonpatch==1.33\n",
      "jsonpointer==2.4\n",
      "jsonschema==4.21.1\n",
      "jsonschema-specifications==2023.12.1\n",
      "jupyter-events==0.10.0\n",
      "jupyter-lsp==2.2.4\n",
      "jupyter-server-mathjax==0.2.6\n",
      "jupyter_client==8.6.1\n",
      "jupyter_core==5.7.2\n",
      "jupyter_server==2.13.0\n",
      "jupyter_server_terminals==0.5.3\n",
      "jupyterlab==4.1.5\n",
      "jupyterlab_git==0.50.0\n",
      "jupyterlab_pygments==0.3.0\n",
      "jupyterlab_server==2.25.4\n",
      "jupyterlab_widgets==3.0.10\n",
      "kiwisolver==1.4.5\n",
      "langchain==0.1.14\n",
      "langchain-community==0.0.30\n",
      "langchain-core==0.1.37\n",
      "langchain-text-splitters==0.0.1\n",
      "langsmith==0.1.38\n",
      "MarkupSafe==2.1.5\n",
      "marshmallow==3.21.1\n",
      "matplotlib==3.7.0\n",
      "matplotlib-inline==0.1.6\n",
      "mistune==3.0.2\n",
      "mpmath==1.3.0\n",
      "multidict==6.0.5\n",
      "mypy-extensions==1.0.0\n",
      "nbclient==0.10.0\n",
      "nbconvert==7.16.2\n",
      "nbdime==4.0.1\n",
      "nbformat==5.10.3\n",
      "nest-asyncio==1.6.0\n",
      "networkx==3.2.1\n",
      "notebook==7.1.2\n",
      "notebook_shim==0.2.4\n",
      "numpy==1.24.2\n",
      "nvidia-cublas-cu12==12.1.3.1\n",
      "nvidia-cuda-cupti-cu12==12.1.105\n",
      "nvidia-cuda-nvrtc-cu12==12.1.105\n",
      "nvidia-cuda-runtime-cu12==12.1.105\n",
      "nvidia-cudnn-cu12==8.9.2.26\n",
      "nvidia-cufft-cu12==11.0.2.54\n",
      "nvidia-curand-cu12==10.3.2.106\n",
      "nvidia-cusolver-cu12==11.4.5.107\n",
      "nvidia-cusparse-cu12==12.1.0.106\n",
      "nvidia-nccl-cu12==2.19.3\n",
      "nvidia-nvjitlink-cu12==12.4.99\n",
      "nvidia-nvtx-cu12==12.1.105\n",
      "openai==1.14.3\n",
      "orjson==3.10.0\n",
      "overrides==7.7.0\n",
      "packaging==23.2\n",
      "pandas==1.5.3\n",
      "pandocfilters==1.5.1\n",
      "parso==0.8.3\n",
      "pexpect==4.9.0\n",
      "pillow==10.2.0\n",
      "platformdirs==4.2.0\n",
      "plotly==5.20.0\n",
      "prometheus_client==0.20.0\n",
      "prompt-toolkit==3.0.43\n",
      "psutil==5.9.8\n",
      "ptyprocess==0.7.0\n",
      "pure-eval==0.2.2\n",
      "pycparser==2.21\n",
      "pydantic==2.6.4\n",
      "pydantic_core==2.16.3\n",
      "Pygments==2.17.2\n",
      "pyparsing==3.1.2\n",
      "python-dateutil==2.9.0.post0\n",
      "python-dotenv==1.0.1\n",
      "python-json-logger==2.0.7\n",
      "pytz==2024.1\n",
      "PyYAML==6.0.1\n",
      "pyzmq==25.1.2\n",
      "referencing==0.34.0\n",
      "requests==2.31.0\n",
      "rfc3339-validator==0.1.4\n",
      "rfc3986-validator==0.1.1\n",
      "rpds-py==0.18.0\n",
      "scikit-learn==1.4.1.post1\n",
      "scipy==1.12.0\n",
      "seaborn==0.13.2\n",
      "Send2Trash==1.8.2\n",
      "six==1.16.0\n",
      "smmap==5.0.1\n",
      "sniffio==1.3.1\n",
      "soupsieve==2.5\n",
      "SQLAlchemy==2.0.29\n",
      "stack-data==0.6.3\n",
      "sympy==1.12\n",
      "tenacity==8.2.3\n",
      "terminado==0.18.1\n",
      "threadpoolctl==3.4.0\n",
      "tinycss2==1.2.1\n",
      "tomli==2.0.1\n",
      "torch==1.12.1\n",
      "torchvision==0.13.1\n",
      "tornado==6.4\n",
      "tqdm==4.64.0\n",
      "traitlets==5.14.2\n",
      "triton==2.2.0\n",
      "types-python-dateutil==2.9.0.20240316\n",
      "typing-inspect==0.9.0\n",
      "typing_extensions==4.10.0\n",
      "tzdata==2024.1\n",
      "uri-template==1.3.0\n",
      "urllib3==2.0.7\n",
      "wcwidth==0.2.13\n",
      "webcolors==1.13\n",
      "webencodings==0.5.1\n",
      "websocket-client==1.7.0\n",
      "widgetsnbextension==3.6.6\n",
      "yarl==1.9.4\n"
     ]
    }
   ],
   "source": [
    "!pip freeze"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
